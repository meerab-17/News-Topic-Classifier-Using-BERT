# -*- coding: utf-8 -*-
"""newsTopicClassifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MI4lk2UegfI3ACZf51A93X0FUPgwTsgV

Problem Statement: To build an intelligent system that can automatically classify news headlines into predefined categories such as World, Sports, Business, and Sci/Tech.
"""

from datasets import load_dataset
from transformers import BertTokenizerFast

dataset = load_dataset("ag_news")
print("loaded")
print(dataset)

tokenizer = BertTokenizerFast.from_pretrained("bert-base-uncased")

def tokenize(batch):
    return tokenizer(batch["text"], padding="max_length", truncation=True, max_length=64)

tokenized_dataset = dataset.map(tokenize, batched=True)
print("Tokenization complete!")
print(tokenized_dataset)

from transformers import BertForSequenceClassification, TrainingArguments, Trainer
import torch

tokenized_dataset = tokenized_dataset.rename_column("label", "labels")
tokenized_dataset.set_format(type="torch", columns=["input_ids", "attention_mask", "labels"])

train_dataset = tokenized_dataset["train"]
test_dataset = tokenized_dataset["test"]

model = BertForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=4)

training_args = TrainingArguments(
    output_dir="./results",
    num_train_epochs=1,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    logging_dir="./logs",
    logging_steps=50
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=test_dataset
)

trainer.train()

#model evaluation
from sklearn.metrics import accuracy_score, f1_score, classification_report

# predictions
predictions = trainer.predict(test_dataset)
preds = predictions.predictions.argmax(axis=1)
labels = predictions.label_ids

# metrics calculation
acc = accuracy_score(labels, preds)
f1 = f1_score(labels, preds, average='weighted')

print(f"Test Accuracy: {acc:.4f}")
print(f"Test F1-score: {f1:.4f}")
print("\nClassification Report:")
print(classification_report(labels, preds))

model.save_pretrained("./saved_model")
tokenizer.save_pretrained("./saved_model")

"""This task involves building a text classification model using the AG News dataset. A pre-trained BERT model (bert-base-uncased) is fine-tuned to predict the topic of a news headline. The process includes data preprocessing, model training, evaluation using accuracy and F1-score, and deployment via a simple Streamlit interface for live user interaction.


"""